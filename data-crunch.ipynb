{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Data\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "Below are brief explanations of what data we are importing and what these variables represent\n",
    "* `ALL_DATA` _(data frame)_ - is our main data set \n",
    "* `poke_types` _(data frame)_ - is a seperate data set that contains a mapping of Pokemon IDs to pokemon name and types. This will be important as our main dependant variable will be **Pokemon type**\n",
    "* `pokemonId_ALL` _(list/array)_ - of all unique pokemon IDs that exist in `ALL_DATA` from smallest to biggest number. \n",
    "\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd # data frames\n",
    "import numpy as np # ____number generation\n",
    "import statsmodels.formula.api as smf # for linear modeling\n",
    "import matplotlib.pyplot as plt # plotting\n",
    "\n",
    "import os.path # check if data file already exists\n",
    "import json # save dictionary strucs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mbyts\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3020: DtypeWarning: Columns (49) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "ALL_DATA = pd.read_csv('data/300k.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "poke_types = pd.read_csv('data/pokeId.csv')\n",
    "poke_types = poke_types[['#', \"Name\", \"Type 1\", \"Type 2\"]]\n",
    "pokemonId_ALL = set(ALL_DATA.pokemonId)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "## Small Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def printAllFeatures():\n",
    "    cols = ALL_DATA.columns\n",
    "    for col in cols:\n",
    "        print(col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "## Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Good, you already have the Poke ID to Poke Type+Name dict. Move on.\n"
     ]
    }
   ],
   "source": [
    "# Create a mapping of IDs to type, secondary type, and name. We need to do this in order to add the\n",
    "# appropriate type to each pokemon in our main data set.\n",
    "\n",
    "pokeId_toType = {}\n",
    "\n",
    "if not os.path.exists(\"data/pokeId_toType.json\"): \n",
    "    \n",
    "    print(\"Looks like you don't have the Pokemon ID to pokemon Type+Name dictionary.\\nLet me go build that for you.\\nStarting... \")\n",
    "    \n",
    "    # build dictionary and save it for future uses\n",
    "    for index, row in poke_types.iterrows():\n",
    "        if row[\"#\"] in pokemonId_ALL: #only add poke that are in main data set\n",
    "            pokeId_toType[str(row[\"#\"])] = [row[\"Name\"] ,row[\"Type 1\"], row[\"Type 2\"]]\n",
    "    \n",
    "    print(\"Saving dictionary locally for future uses.\")\n",
    "    with open(\"data/pokeId_toType.json\", 'w') as f:\n",
    "        json.dump(pokeId_toType, f)\n",
    "    print(\"...Done\")\n",
    "else:\n",
    "    print(\"Good, you already have the Poke ID to Poke Type+Name dict. Move on.\")    \n",
    "    with open(\"data/pokeId_toType.json\") as f:\n",
    "        pokeId_toType = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Good job, you already have the merged data. Move on.\n"
     ]
    }
   ],
   "source": [
    "# Check if you have the merged data set. If you do not then build and save it locally.\n",
    "# The print statements do a good job of informing what's going on.\n",
    "\n",
    "if not os.path.exists(\"data/merged.csv\"): \n",
    "    \n",
    "    print(\"Hey looks like you're missing the merged data, let me build that for you, it'll take 2-5 minutes probably.\\n\")\n",
    "    \n",
    "    # Add the new columns\n",
    "    ALL_DATA[\"Name\"] = \"\"\n",
    "    ALL_DATA[\"Type\"] = \"\" \n",
    "\n",
    "    def update_row(row):\n",
    "        tempTypes = pokeId_toType[str(row[\"pokemonId\"])]   \n",
    "        listy = [tempTypes[0], tempTypes[1]]\n",
    "        return pd.Series(listy)\n",
    "\n",
    "    print(\"Merging data...\")\n",
    "    ALL_DATA[['Name', 'Type']] = ALL_DATA.apply(update_row, axis=1)\n",
    "    print(\"Done merging data.\\n\")\n",
    "\n",
    "    print(\"Saving merge data set to ./data/merged.csv\")\n",
    "    ALL_DATA.to_csv(\"data/merged.csv\",index=False)\n",
    "    print(\"\\n...Done saving data. Move on now.\\n\")\n",
    "    ALL_DATA.head()\n",
    "else:\n",
    "    ALL_DATA = pd.read_csv('data/merged.csv')\n",
    "    print(\"Good job, you already have the merged data. Move on.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "### Encoding\n",
    "\n",
    "We cannot use categorical data (strings) in feature selection or regressions.\n",
    "The solution to this is to turn strings into numerical data mappings in order to be able to process them.\n",
    "Based on my research there are three beginner friendly functions that do this. \n",
    "\n",
    "`sklearn` has the functions `LabelEncoder()` and `OneHotEncoder()` -- and `pandas` has its own functions `get_dummies()`.\n",
    "\n",
    "I selected the `get_dummies()` as both it and my data frames are managed with the `pandas` library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "DATA_encoded = ALL_DATA.dropna()\n",
    "\n",
    "# These columns are of type objects but are not helpful to us.\n",
    "DATA_encoded = DATA_encoded.drop([\"appearedLocalTime\", \"appearedDayOfWeek\", \"_id\", \"city\", \"weatherIcon\", \"Name\"], axis=1) ########## Question from Maggie - Do we want to keep name, would it help our results or nah? \n",
    "\n",
    "# it's an object column but should be float: convert it.\n",
    "DATA_encoded[\"pokestopDistanceKm\"] = DATA_encoded[\"pokestopDistanceKm\"].apply(pd.to_numeric, downcast='float', errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding <appearedTimeOfDay>.\n",
      "Encoding <continent>.\n",
      "Encoding <weather>.\n",
      "...Done encoding.\n"
     ]
    }
   ],
   "source": [
    "# anything of type object seems to be categorical, encode it.\n",
    "\n",
    "# produce dummies for categorical columns, concat them to data, remove originals\n",
    "\n",
    "# get_dummies() code:\n",
    "# https://towardsdatascience.com/the-dummys-guide-to-creating-dummy-variables-f21faddb1d40\n",
    "\n",
    "cols_toNotTouch = [\"Type\"]\n",
    "\n",
    "for col in DATA_encoded.columns:\n",
    "    if (str(DATA_encoded[col].dtype) == 'object') and (not(col in cols_toNotTouch)):\n",
    "        \n",
    "        print(\"Encoding <\" + col + \">.\")\n",
    "        dummy = pd.get_dummies(DATA_encoded[col])\n",
    "        DATA_encoded = DATA_encoded.drop([col], axis=1)\n",
    "        DATA_encoded = pd.concat([DATA_encoded, dummy], axis=1)\n",
    "print(\"...Done encoding.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ONLY ONE SPLIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train features shape (236816, 242)\n",
      "test features shape (59205, 242)\n",
      "\n",
      "train outcomes shape (236816,)\n",
      "test outcomes shape (59205,)\n"
     ]
    }
   ],
   "source": [
    "# Split data\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_X, test_X, train_Y, test_Y = train_test_split(\n",
    "                                       DATA_encoded,      # features\n",
    "                                        DATA_encoded.Type,                               \n",
    "#     ALL_DATA[\"Type\"],    # outcome ######################### CHANGE TO ---> DATA_encoded.Type \n",
    "                                       test_size=0.20, # percentage of data to use as the test set\n",
    "                                       random_state=15 # set a random state so it is consistent (not required!)\n",
    "                                                                            )\n",
    "\n",
    "print(\"train features shape\", train_X.shape)\n",
    "print(\"test features shape\", test_X.shape)\n",
    "print()\n",
    "print(\"train outcomes shape\", train_Y.shape)\n",
    "print(\"test outcomes shape\", test_Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = train_X.dropna()\n",
    "train_Y = train_X[\"Type\"]\n",
    "\n",
    "test_X = train_X.dropna()\n",
    "test_Y = train_X[\"Type\"]\n",
    "\n",
    "train_X_for_modeling = train_X.copy()\n",
    "test_X_for_modeling = test_X.copy()\n",
    "\n",
    "\n",
    "train_X_results = train_X.Type\n",
    "test_X_results = test_X.Type\n",
    "\n",
    "\n",
    "# Put this in if (has Type column)\n",
    "train_X = train_X.drop([\"Type\"], axis=1)\n",
    "test_X = test_X.drop([\"Type\"], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "## Feature Selection - REVISIT LATER --- CHANGE OLS TO CATEGORIAL\n",
    "\n",
    "https://stackoverflow.com/questions/30384995/randomforestclassfier-fit-valueerror-could-not-convert-string-to-float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "code_folding": [
     3
    ]
   },
   "outputs": [],
   "source": [
    "import statsmodels.formula.api as smf\n",
    "\n",
    "# Code from https://planspace.org/20150423-forward_selection_with_statsmodels/\n",
    "def forward_selected(data, response):\n",
    "    \"\"\"Linear model designed by forward selection.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    data : pandas DataFrame with all possible predictors and response\n",
    "\n",
    "    response: string, name of response column in data\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    model: an \"optimal\" fitted statsmodels linear model\n",
    "           with an intercept\n",
    "           selected by forward selection\n",
    "           evaluated by adjusted R-squared\n",
    "    \"\"\"\n",
    "    remaining = set(data.columns)\n",
    "    remaining.remove(response)\n",
    "    selected = []\n",
    "    current_score, best_new_score = 0.0, 0.0\n",
    "    while remaining and current_score == best_new_score:\n",
    "        scores_with_candidates = []\n",
    "        for candidate in remaining:\n",
    "            formula = \"{} ~ {} + 1\".format(response,\n",
    "                                           ' + '.join(selected + [candidate]))\n",
    "            score = smf.ols(formula, data).fit().rsquared_adj\n",
    "            scores_with_candidates.append((score, candidate))\n",
    "        scores_with_candidates.sort()\n",
    "        best_new_score, best_candidate = scores_with_candidates.pop()\n",
    "        if current_score < best_new_score:\n",
    "            remaining.remove(best_candidate)\n",
    "            selected.append(best_candidate)\n",
    "            current_score = best_new_score\n",
    "    formula = \"{} ~ {} + 1\".format(response,\n",
    "                                   ' + '.join(selected))\n",
    "    model = smf.ols(formula, data).fit()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "283775     Normal\n",
       "172953     Poison\n",
       "207540    Psychic\n",
       "8640       Ground\n",
       "236838     Normal\n",
       "215075    Psychic\n",
       "85849      Normal\n",
       "76754      Normal\n",
       "231024        Bug\n",
       "225167      Grass\n",
       "291219     Normal\n",
       "210651      Water\n",
       "235820    Psychic\n",
       "107576      Water\n",
       "271009        Bug\n",
       "274955     Normal\n",
       "103739        Bug\n",
       "78193     Psychic\n",
       "123810      Water\n",
       "225617        Bug\n",
       "132861        Bug\n",
       "140647     Normal\n",
       "184356     Normal\n",
       "112858     Normal\n",
       "241116    Psychic\n",
       "37549       Water\n",
       "134498      Grass\n",
       "97985      Ground\n",
       "276829        Bug\n",
       "52617       Water\n",
       "           ...   \n",
       "80227      Normal\n",
       "15311      Normal\n",
       "22632      Normal\n",
       "52530      Normal\n",
       "282522      Water\n",
       "35413       Ghost\n",
       "71776      Normal\n",
       "152479        Bug\n",
       "94209         Bug\n",
       "28774      Poison\n",
       "206159        Bug\n",
       "117692      Grass\n",
       "1063         Fire\n",
       "275305        Bug\n",
       "106639     Normal\n",
       "117514     Normal\n",
       "90528         Bug\n",
       "201631        Bug\n",
       "133137      Grass\n",
       "139485        Bug\n",
       "45999      Normal\n",
       "217718     Normal\n",
       "30411      Normal\n",
       "44231      Normal\n",
       "35483         Bug\n",
       "104832     Normal\n",
       "180087      Ghost\n",
       "199301      Water\n",
       "270220     Normal\n",
       "269768    Psychic\n",
       "Name: Type, Length: 236816, dtype: object"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model = forward_selected(new_df, 'total_cases')\n",
    "# print(model.model.formula)\n",
    "# print(model.rsquared_adj)\n",
    "# model.summary()\n",
    "\n",
    "\n",
    "# model = forward_selected(train_X, \"Type\")\n",
    "# print(model.model.formula)\n",
    "# print(model.rsquared_adj)\n",
    "# model.summary()\n",
    "train_X.Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "shapes (236816,15) and (236816,15) not aligned: 15 (dim 1) != 236816 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-5b260634f32f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mforward_selected\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Type\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformula\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrsquared_adj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-19-f1b46860650a>\u001b[0m in \u001b[0;36mforward_selected\u001b[1;34m(data, response)\u001b[0m\n\u001b[0;32m     27\u001b[0m             formula = \"{} ~ {} + 1\".format(response,\n\u001b[0;32m     28\u001b[0m                                            ' + '.join(selected + [candidate]))\n\u001b[1;32m---> 29\u001b[1;33m             \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msmf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mols\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mformula\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrsquared_adj\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     30\u001b[0m             \u001b[0mscores_with_candidates\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcandidate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m         \u001b[0mscores_with_candidates\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\wrapper.py\u001b[0m in \u001b[0;36m__getattribute__\u001b[1;34m(self, attr)\u001b[0m\n\u001b[0;32m     33\u001b[0m             \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 35\u001b[1;33m         \u001b[0mobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     36\u001b[0m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m         \u001b[0mhow\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_wrap_attrs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mattr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\statsmodels\\tools\\decorators.py\u001b[0m in \u001b[0;36m__get__\u001b[1;34m(self, obj, type)\u001b[0m\n\u001b[0;32m     95\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0m_cachedval\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     96\u001b[0m             \u001b[1;31m# Call the \"fget\" function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 97\u001b[1;33m             \u001b[0m_cachedval\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     98\u001b[0m             \u001b[1;31m# Set the attribute in obj\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m             \u001b[1;31m# print(\"Setting %s in cache to %s\" % (name, _cachedval))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\statsmodels\\regression\\linear_model.py\u001b[0m in \u001b[0;36mrsquared_adj\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1548\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mrsquared_adj\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1549\u001b[0m         return 1 - (np.divide(self.nobs - self.k_constant, self.df_resid)\n\u001b[1;32m-> 1550\u001b[1;33m                     * (1 - self.rsquared))\n\u001b[0m\u001b[0;32m   1551\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1552\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mcache_readonly\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\statsmodels\\tools\\decorators.py\u001b[0m in \u001b[0;36m__get__\u001b[1;34m(self, obj, type)\u001b[0m\n\u001b[0;32m     95\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0m_cachedval\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     96\u001b[0m             \u001b[1;31m# Call the \"fget\" function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 97\u001b[1;33m             \u001b[0m_cachedval\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     98\u001b[0m             \u001b[1;31m# Set the attribute in obj\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m             \u001b[1;31m# print(\"Setting %s in cache to %s\" % (name, _cachedval))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\statsmodels\\regression\\linear_model.py\u001b[0m in \u001b[0;36mrsquared\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1541\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mrsquared\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1542\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mk_constant\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1543\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mssr\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcentered_tss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1544\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1545\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mssr\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muncentered_tss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\statsmodels\\tools\\decorators.py\u001b[0m in \u001b[0;36m__get__\u001b[1;34m(self, obj, type)\u001b[0m\n\u001b[0;32m     95\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0m_cachedval\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     96\u001b[0m             \u001b[1;31m# Call the \"fget\" function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 97\u001b[1;33m             \u001b[0m_cachedval\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     98\u001b[0m             \u001b[1;31m# Set the attribute in obj\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m             \u001b[1;31m# print(\"Setting %s in cache to %s\" % (name, _cachedval))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\statsmodels\\regression\\linear_model.py\u001b[0m in \u001b[0;36mssr\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1513\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mssr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1514\u001b[0m         \u001b[0mwresid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwresid\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1515\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwresid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwresid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1516\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1517\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mcache_readonly\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: shapes (236816,15) and (236816,15) not aligned: 15 (dim 1) != 236816 (dim 0)"
     ]
    }
   ],
   "source": [
    "# model = forward_selected(new_df, 'total_cases')\n",
    "# print(model.model.formula)\n",
    "# print(model.rsquared_adj)\n",
    "# model.summary()\n",
    "\n",
    "\n",
    "model = forward_selected(train_X, \"Type\")\n",
    "print(model.model.formula)\n",
    "print(model.rsquared_adj)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "# ------------------------------------ ALT FEATURE SELECTION BELOW--------------------------------------------\n",
    "\n",
    "forward feature selection using Lasso regression:\n",
    "https://mikulskibartosz.name/forward-feature-selection-in-scikit-learn-f6476e474ddd\n",
    "\n",
    "* Uses regularization to prevent overfitting\n",
    "* Sets the coefficients of unimportant variables to 0\n",
    "* Don't forget to smash that subscribe button\n",
    "* For every 'Like' on this jupyter notebook, an INFO student yodels \"The iSchool is MySchool!\"\n",
    "* Delete the last three bullets before submitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Made a change in 'outcomes' variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train features shape (236816, 242)\n",
      "test features shape (59205, 242)\n",
      "\n",
      "train outcomes shape (236816,)\n",
      "test outcomes shape (59205,)\n"
     ]
    }
   ],
   "source": [
    "# # Split data\n",
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# train_X2, test_X2, train_Y2, test_Y2 = train_test_split(\n",
    "    \n",
    "#                                        DATA_encoded,      # features\n",
    "#                                        DATA_encoded.Type, # outcomes\n",
    "# #                                        TEST_DF,      # features\n",
    "# #                                        TEST_DF.Type, # outcomes\n",
    "#                                        test_size=0.20, # percentage of data to use as the test set\n",
    "#                                        random_state=15 # set a random state so it is consistent (not required!)\n",
    "#                                                                             )\n",
    "\n",
    "# print(\"train features shape\", train_X2.shape)\n",
    "# print(\"test features shape\", test_X2.shape)\n",
    "# print()\n",
    "# print(\"train outcomes shape\", train_Y2.shape)\n",
    "# print(\"test outcomes shape\", test_Y2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_X = train_X.dropna()\n",
    "\n",
    "# train_X_results = train_X2.Type\n",
    "# train_X = train_X2.drop(\"Type\", axis=1)\n",
    "\n",
    "# test_X_results = test_X2.Type\n",
    "# test_X2 = test_X2.drop(\"Type\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create array of encoded Pokemon Types\n",
    "# pokemon_unique_types = list(train_X2_results.unique())\n",
    "# type_float = []\n",
    "# for val in train_X2_results:\n",
    "#     type_float.append(pokemon_unique_types.index(val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Code Reference: https://mikulskibartosz.name/forward-feature-selection-in-scikit-learn-f6476e474ddd\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "X = train_X.drop([\"pokemonId\", \"class\"], axis=1) # Drop columns that directly affect Pokemon Type\n",
    "y = train_X_results\n",
    "estimator = Lasso()\n",
    "featureSelection = SelectFromModel(estimator)\n",
    "featureSelection.fit(X, y)\n",
    "selectedFeatures = featureSelection.transform(X)\n",
    "selectedFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['longitude', 'sunriseMinutesMidnight', 'sunsetMinutesMidnight',\n",
       "       'population_density'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get features that most affect the Pokemon Type predictions\n",
    "X.columns[featureSelection.get_support()]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ending Notes/Ides:\n",
    "\n",
    "* The line above returns columns - 'longitude', 'sunriseMinutesMidnight', 'sunsetMinutesMidnight', 'population_density'\n",
    "* Drop irrelevant columns in 'X' above for a more narrow scope of features when modeling iterations (out of all the columns, which weather data is best etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# --------------END OF ALT FEATURE SELECTION --------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "dtree_model = DecisionTreeClassifier(max_depth = 2).fit(train_X, train_Y) \n",
    "dtree_predictions = dtree_model.predict(test_X) \n",
    "accuracy_score(test_Y, dtree_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn_clf = KNeighborsClassifier(n_neighbors=3)\n",
    "knn_model = knn_clf.fit(train_X, train_Y)\n",
    "preds = knn_model.predict(test_X)\n",
    "accuracy_score(test_Y, preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiclass regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVC Regression\n",
    "\n",
    "Meant for working with categorical data.\n",
    "Grab subset sample data for SVC regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_train_X = train_X_for_modeling.sample(frac=0.01)\n",
    "sample_train_Y = sample_train_X.Type\n",
    "sample_train_X = sample_train_X.drop(\"Type\", axis=1)\n",
    "\n",
    "sample_test_X = test_X_for_modeling.sample(frac=0.01)\n",
    "sample_test_Y = sample_test_X.Type\n",
    "sample_train_X = sample_test_X.drop(\"Type\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'index'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-f4536be0b04b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mencoded_sample_train_Y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mval\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msample_train_Y\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mencoded_sample_train_Y\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0munique_types\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'index'"
     ]
    }
   ],
   "source": [
    "unique_types = sample_train_Y.unique()\n",
    "\n",
    "encoded_sample_train_Y = []\n",
    "for val in sample_train_Y:\n",
    "    encoded_sample_train_Y.append(unique_types.index(val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mbyts\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC \n",
    "svm_model_linear = SVC(C = 1).fit(sample_train_X, sample_train_Y) \n",
    "svm_predictions = svm_model_linear.predict(sample_test_X) \n",
    "accuracy = svm_model_linear.score(sample_test_X, sample_test_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Search\n",
    "\n",
    "Determine best neighbors and depth level for models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mbyts\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:652: Warning: The least populated class in y has only 4 members, which is too few. The minimum number of members in any class cannot be less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), Warning)\n",
      "C:\\Users\\mbyts\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'Normal'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-889a808477ae>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mgrid_search\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msample_train_X\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_train_Y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mknn_params\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgrid_search\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcv_results_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'params'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mgrid_search\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_index_\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mknn_score\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgrid_search\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msample_test_X\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_test_Y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"KNN params:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mknn_params\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"KNN score:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mknn_score\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mscore\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    460\u001b[0m                              % self.best_estimator_)\n\u001b[0;32m    461\u001b[0m         \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscorer_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrefit\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmultimetric_\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscorer_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 462\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    463\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    464\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_check_is_fitted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\scorer.py\u001b[0m in \u001b[0;36m_passthrough_scorer\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m    239\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_passthrough_scorer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    240\u001b[0m     \u001b[1;34m\"\"\"Function that wraps estimator.score\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 241\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    242\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    243\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36mscore\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    286\u001b[0m         \"\"\"\n\u001b[0;32m    287\u001b[0m         \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 288\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    289\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    290\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\classification.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    145\u001b[0m             \u001b[0mClass\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0meach\u001b[0m \u001b[0mdata\u001b[0m \u001b[0msample\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    146\u001b[0m         \"\"\"\n\u001b[1;32m--> 147\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'csr'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    148\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m         \u001b[0mneigh_dist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mneigh_ind\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkneighbors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    565\u001b[0m         \u001b[1;31m# make sure we actually converted to numeric:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    566\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mdtype_numeric\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"O\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 567\u001b[1;33m             \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    568\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mallow_nd\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    569\u001b[0m             raise ValueError(\"Found array with dim %d. %s expected <= 2.\"\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: 'Normal'"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# for KNN\n",
    "param_grid = {'n_neighbors':range(1, 6), 'weights':[\"uniform\", \"distance\"]}\n",
    "grid_search = GridSearchCV(KNeighborsClassifier(), param_grid, cv=5, return_train_score=True)\n",
    "grid_search.fit(sample_train_X, sample_train_Y)\n",
    "knn_params = grid_search.cv_results_['params'][grid_search.best_index_]\n",
    "knn_score = grid_search.score(sample_test_X, sample_test_Y)\n",
    "print(\"KNN params:\", knn_params, \"KNN score:\", knn_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for Decision Tree\n",
    "param_grid_tree = {'random_state': np.arange(1, 5)}\n",
    "tree_grid = GridSearchCV(DecisionTreeClassifier(), param_grid_tree, cv=5, return_train_score=True)\n",
    "tree_grid.fit(train_X, train_Y)\n",
    "tree_params = tree_grid.cv_results_['params'][tree_grid.best_index_]\n",
    "tree_score = tree_grid.score(test_X, test_Y)\n",
    "print(\"Tree params:\", tree_params, \"Tree score:\", tree_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "### Ending Thoughts\n",
    "\n",
    "> feature selection - what to do?\n",
    "> compare accuracies\n",
    "> See per type - create results df, compare how accurate predictions are for <type>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
